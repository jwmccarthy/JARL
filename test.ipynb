{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from jarl.modules.mlp import MLP\n",
    "from jarl.envs.gym import TorchGymEnv\n",
    "from jarl.data.dict import DotDict\n",
    "from jarl.data.buffer import LazyBuffer\n",
    "from jarl.modules.operator import Critic\n",
    "from jarl.modules.encoder import FlattenEncoder\n",
    "from jarl.modules.policy import CategoricalPolicy\n",
    "\n",
    "from jarl.train.optim import Optimizer\n",
    "from jarl.train.update.critic import MSECriticUpdate\n",
    "from jarl.train.update.policy import ClippedPolicyUpdate\n",
    "from jarl.train.update.ppo import PPOUpdate\n",
    "from jarl.train.graph import TrainGraph\n",
    "from jarl.train.sample.base import BatchSampler\n",
    "from jarl.modules.discriminator import Discriminator\n",
    "\n",
    "from jarl.train.modify.compute import (\n",
    "    ComputeValues,\n",
    "    ComputeLogProbs,\n",
    "    ComputeAdvantages,\n",
    "    ComputeReturns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env = TorchGymEnv(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = CategoricalPolicy(\n",
    "    head=FlattenEncoder(),\n",
    "    body=MLP(func=nn.Tanh, dims=[64, 64])\n",
    ").build(env)\n",
    "\n",
    "critic = Critic(\n",
    "    head=FlattenEncoder(), \n",
    "    body=MLP(func=nn.Tanh, dims=[64, 64]),\n",
    ").build(env)\n",
    "\n",
    "discrim = Discriminator(\n",
    "    head=FlattenEncoder(),\n",
    "    body=MLP(func=nn.Tanh, dims=[64, 64])\n",
    ").build(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_block = (\n",
    "    TrainGraph(\n",
    "        BatchSampler(64, num_epoch=10),\n",
    "        PPOUpdate(\n",
    "            2048, policy, critic, optimizer=Optimizer(Adam, lr=3e-4), ent_coef=0.01\n",
    "        )\n",
    "    )\n",
    "    .add_modifier(ComputeAdvantages())\n",
    "    .add_modifier(ComputeLogProbs(policy))\n",
    "    .add_modifier(ComputeReturns())\n",
    "    .add_modifier(ComputeValues(critic))\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_episodic_return(data):\n",
    "    don = data.don\n",
    "    rew = data.rew\n",
    "    ret = []\n",
    "    ep_ret = 0\n",
    "    for i, d in enumerate(don):\n",
    "        ep_ret += rew[i].item()\n",
    "        if d:\n",
    "            ret.append(ep_ret)\n",
    "            ep_ret = 0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 {'policy_loss': -0.000940173864364624, 'entropy_loss': -0.0136715704575181, 'approx_kl': -0.014608027413487434, 'critic_loss': 826.2957763671875, 'rew': -184.9752837061428}\n",
      "4096 {'policy_loss': -0.034572310745716095, 'entropy_loss': -0.013655910268425941, 'approx_kl': 0.00018473342061042786, 'critic_loss': 584.3338012695312, 'rew': -164.99507585993038}\n",
      "6144 {'policy_loss': -0.023270191624760628, 'entropy_loss': -0.013474492356181145, 'approx_kl': -0.005885083228349686, 'critic_loss': 414.9740905761719, 'rew': -161.4258410644741}\n",
      "8192 {'policy_loss': -0.018377017229795456, 'entropy_loss': -0.013279171660542488, 'approx_kl': 0.01239684410393238, 'critic_loss': 364.78143310546875, 'rew': -150.7124396924847}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      8\u001b[0m     trs \u001b[38;5;241m=\u001b[39m DotDict(\n\u001b[1;32m      9\u001b[0m         obs\u001b[38;5;241m=\u001b[39mobs, \n\u001b[1;32m     10\u001b[0m         act\u001b[38;5;241m=\u001b[39mpolicy(obs)\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 12\u001b[0m exp, obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(trs\u001b[38;5;241m=\u001b[39mtrs)\n\u001b[1;32m     13\u001b[0m buffer\u001b[38;5;241m.\u001b[39mstore(exp)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ppo_block\u001b[38;5;241m.\u001b[39mready(t):\n",
      "File \u001b[0;32m~/Documents/RL/JARL/jarl/envs/gym.py:44\u001b[0m, in \u001b[0;36mTorchGymEnv.step\u001b[0;34m(self, act, trs, stop)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# init transition if needed\u001b[39;00m\n\u001b[1;32m     42\u001b[0m trs \u001b[38;5;241m=\u001b[39m trs \u001b[38;5;129;01mor\u001b[39;00m DotDict(act\u001b[38;5;241m=\u001b[39mact)\n\u001b[0;32m---> 44\u001b[0m obs, rew, trm, trc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step(trs\u001b[38;5;241m.\u001b[39mact)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# non-space vals to tensors\u001b[39;00m\n\u001b[1;32m     47\u001b[0m trs\u001b[38;5;241m.\u001b[39mrew \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mas_tensor(rew, dtype\u001b[38;5;241m=\u001b[39mth\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Documents/RL/JARL/jarl/envs/gym.py:31\u001b[0m, in \u001b[0;36mTorchGymEnv._step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action, Tensor):\n\u001b[1;32m     30\u001b[0m     action \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gymnasium/envs/box2d/lunar_lander.py:631\u001b[0m, in \u001b[0;36mLunarLander.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    617\u001b[0m         p\u001b[38;5;241m.\u001b[39mApplyLinearImpulse(\n\u001b[1;32m    618\u001b[0m             (\n\u001b[1;32m    619\u001b[0m                 ox \u001b[38;5;241m*\u001b[39m SIDE_ENGINE_POWER \u001b[38;5;241m*\u001b[39m s_power,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    624\u001b[0m         )\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlander\u001b[38;5;241m.\u001b[39mApplyLinearImpulse(\n\u001b[1;32m    626\u001b[0m         (\u001b[38;5;241m-\u001b[39mox \u001b[38;5;241m*\u001b[39m SIDE_ENGINE_POWER \u001b[38;5;241m*\u001b[39m s_power, \u001b[38;5;241m-\u001b[39moy \u001b[38;5;241m*\u001b[39m SIDE_ENGINE_POWER \u001b[38;5;241m*\u001b[39m s_power),\n\u001b[1;32m    627\u001b[0m         impulse_pos,\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[0;32m--> 631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    633\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlander\u001b[38;5;241m.\u001b[39mposition\n\u001b[1;32m    634\u001b[0m vel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlander\u001b[38;5;241m.\u001b[39mlinearVelocity\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "buffer = LazyBuffer(2048)\n",
    "\n",
    "rews = []\n",
    "\n",
    "obs = env.reset()\n",
    "for t in range(int(1e6)):\n",
    "    with th.no_grad():\n",
    "        trs = DotDict(\n",
    "            obs=obs, \n",
    "            act=policy(obs)\n",
    "        )\n",
    "    exp, obs = env.step(trs=trs)\n",
    "    buffer.store(exp)\n",
    "\n",
    "    if ppo_block.ready(t):\n",
    "        data = buffer.serve()\n",
    "        batch_info = ppo_block.update(data)\n",
    "        rews.extend(get_episodic_return(data))\n",
    "        batch_info.update()\n",
    "        print(t, batch_info | dict(rew=np.mean(rews[-100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
